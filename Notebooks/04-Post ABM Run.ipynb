{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3c47d72-ed5f-474e-b50a-21ee434b327b",
   "metadata": {},
   "source": [
    "# Post Sim Run\n",
    "\n",
    "This takes the simulation output and does some maths to get it to look exactly like the GPS output. This is intended to allow both sim and gps datasets to run trhough the same code so that 1:1 comparisons can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eac835-dee9-488b-b135-808848a1cc0d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Import some libs\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "import yaml \n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from math import radians, sin, cos, sqrt, asin\n",
    "\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9968cbfb-cd71-4401-aa4a-4a148f3e93d4",
   "metadata": {},
   "source": [
    "## Config and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39070c4c-be6a-4257-816f-5c7fa11bd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Variables\n",
    "resample = False\n",
    "sample_size = 10000\n",
    "\n",
    "sim_projection = 'EPSG:5070'\n",
    "gps_projection = 'EPSG:4326'\n",
    "\n",
    "chosen_projection = sim_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecf96cc-8578-43ba-b1de-04986d55cecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "##########################\n",
    "config_file = '../config/local_deer_config.yaml'\n",
    "random_csv = '../output/random_vs_disease.csv'\n",
    "hmm_csv = '../output/HMM_vs_disease.csv'\n",
    "hmm_csv = '../output/LocalRun_1.csv'\n",
    "dld_csv = '../output/DLD_vs_disease.csv' \n",
    "\n",
    "# The GPS file that is being used to check against.\n",
    "gps_file = './output-data/filtered_gps.parq'\n",
    "\n",
    "# Output\n",
    "##########################\n",
    "sim_parq = '../output/sim.parq' \n",
    "agent_gpkg = '../output/agent.gpkg'\n",
    "\n",
    "sim_hr_gpkg = '../output/sim_homeranges.gpkg' \n",
    "gps_hr_gpkg = '../output/gps_homeranges.gpkg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc9caa-b501-47b7-931f-d5c6743ef276",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open(config_file) as stream:\n",
    "    try:\n",
    "        params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3574cb7-eb39-4ae6-986b-086e995a1a46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def csv_to_gpkg(params):\n",
    "    '''\n",
    "    Convert the repast csv logfile into a geopackage with \n",
    "    the x,y coords as point geom, and maybe the centroid geom too...\n",
    "    '''\n",
    "    in_csv = params['logging']['agent_log_file']\n",
    "    agent_gpkg = params['logging']['gpkg_log_file']\n",
    "    centroid_gpkg = params['logging']['centroid_log_file']\n",
    "\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(in_csv)\n",
    "\n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df, \n",
    "        geometry=gpd.points_from_xy(df['x'], df['y'], crs='EPSG:5070')\n",
    "    )\n",
    "\n",
    "    # Save to a GeoPackage file\n",
    "    gdf.to_file(agent_gpkg, layer='agent_location', driver='GPKG')\n",
    "\n",
    "    \n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        df, \n",
    "        geometry=gpd.points_from_xy(df['centroid_x'], df['centroid_y'], crs='EPSG:5070')\n",
    "    )\n",
    "\n",
    "    # Save to a GeoPackage file\n",
    "    gdf.to_file(centroid_gpkg, layer='centroid_location', driver='GPKG')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d1bc3d-874a-43b1-8ef9-a03d33dc5c54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def csv_to_parquet_chunked(csv_filepath, parquet_filepath, chunksize=100000):\n",
    "    \"\"\"\n",
    "    Converts a large CSV file to Parquet format in chunks.\n",
    "\n",
    "    Args:\n",
    "        csv_filepath (str): Path to the input CSV file.\n",
    "        parquet_filepath (str): Path to the output Parquet file.\n",
    "        chunksize (int, optional): Number of rows to read per chunk. Defaults to 100000.\n",
    "    \"\"\"\n",
    "    csv_stream = pd.read_csv(csv_filepath, chunksize=chunksize)\n",
    "    \n",
    "    # Get the schema from the first chunk\n",
    "    first_chunk = next(csv_stream)\n",
    "    parquet_schema = pa.Table.from_pandas(first_chunk).schema\n",
    "    \n",
    "    # Initialize Parquet writer\n",
    "    with pq.ParquetWriter(parquet_filepath, schema=parquet_schema) as writer:\n",
    "        # Write the first chunk\n",
    "        table = pa.Table.from_pandas(first_chunk, schema=parquet_schema)\n",
    "        writer.write_table(table)\n",
    "    \n",
    "        # Process remaining chunks\n",
    "        for chunk in csv_stream:\n",
    "            table = pa.Table.from_pandas(chunk, schema=parquet_schema)\n",
    "            writer.write_table(table)\n",
    "\n",
    "# Example usage: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98ba54-3003-4446-8cb8-88bcb296ee3e",
   "metadata": {},
   "source": [
    "## Read Sim Output\n",
    "\n",
    "Read several CSV files that have been created using the \"make benchmark\" command. These files are created using a couple of different config files. The goal here is to compare the different parameters in the benchmark config files.\n",
    "\n",
    "For this experiment one month of data was generated using different \"movement methods\" for each run. The different movement methods are:\n",
    "\n",
    "  - Random Movement: No behaviour states, no landscape interaction, just basic step and turn movement\n",
    "  - HMM Movement: Multiple behaviour states that are set the step and turn parameters. Transistions between states is a result of the landscape data.\n",
    "  - DLD movement: Complex movement influenced by behaviour states, home ranges, landscape info etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4b040d-3833-4a98-a381-c94d8a1bcffa",
   "metadata": {},
   "source": [
    "The csv's are read into a dataframe in chunks and then saved to a parquet file. This should allow larger simulations to be processed on a smaller machine (like my laptop) without running into memory errors... up to a point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4df97d-f8e8-49db-a4a7-01c12056c3df",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "csvs = [random_csv, hmm_csv, dld_csv]\n",
    "# csvs = [ hmm_csv]\n",
    "\n",
    "df_sim = pd.DataFrame()\n",
    "for sim_csv in csvs:\n",
    "    csv_to_parquet_chunked(sim_csv, sim_parq)\n",
    "    df = pd.read_parquet(sim_parq)\n",
    "    df.rename(columns = {'Timestamp':'timestamp',\n",
    "                     'UUID':'ID' },inplace=True)\n",
    "    \n",
    "    filename = os.path.splitext(os.path.basename(sim_csv))[0] \n",
    "    df['filename'] = filename\n",
    "    df_sim = pd.concat([df_sim, df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bf51f-9e8c-47b4-a4c2-6039bf85da28",
   "metadata": {},
   "source": [
    "Convert the parquet file into a geopandas dataframe and eventually a geopackage. This will allow it to be easily added to a QGIS project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e2fb5d-2470-4f13-bb3c-04163d298d82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert to GeoDataFrame\n",
    "gdf_sim = gpd.GeoDataFrame(\n",
    "    df_sim, \n",
    "    geometry=gpd.points_from_xy(df_sim['x_proj'], df_sim['y_proj'], crs=sim_projection)\n",
    ")\n",
    "#Reproject to chosen project projection\n",
    "gdf_sim = gdf_sim.to_crs(chosen_projection)\n",
    "\n",
    "# Save to a GeoPackage file\n",
    "gdf_sim.to_file(agent_gpkg, layer='agent_location', driver='GPKG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c05dd-a6f4-482f-94d2-44c7773f84ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sim.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f55d5c9-3b34-4c27-b053-45d4cbab4ae5",
   "metadata": {},
   "source": [
    "## Read GPS Data\n",
    "Once all the preprocessing has been done, lets read the smaller/compressed parquet file into memory,do some analysis, and start plotting it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bdc312-4583-499d-92ce-74a951daa3f6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_gps = pd.read_parquet(gps_file)\n",
    "gdf_gps = gpd.GeoDataFrame(\n",
    "    df_gps, \n",
    "    geometry=gpd.points_from_xy(df_gps['lon'], df_gps['lat'], crs=gps_projection))\n",
    "\n",
    "#Reproject to chosen project projection\n",
    "gdf_gps = gdf_gps.to_crs(chosen_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4256f0-4531-45b4-a4e4-db8314de4f2c",
   "metadata": {},
   "source": [
    "## Calculate HomeRange Timeseries\n",
    "\n",
    "How much area is covered every week/month/year? Is it similar between the sim and GPS data?\n",
    "\n",
    "Let's take both the GPS data and SIM data and group it by Agent ID, Month and, in the case of the simulation data, the Filename of the data. This is in order to keep the different benchmark results seperate.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882b0f7e-9e34-4dac-a8d3-b7d66fd31abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's calculate the monthly group\n",
    "gdf_sim['timestamp'] = pd.to_datetime(gdf_sim['timestamp'] )\n",
    "gdf_sim['time_group'] = gdf_sim['timestamp'].dt.to_period('M')\n",
    "\n",
    "gdf_gps['timestamp'] = pd.to_datetime(gdf_gps['timestamp'] )\n",
    "gdf_gps['time_group'] = gdf_gps['timestamp'].dt.to_period('M')\n",
    "\n",
    "sim_homeranges = gdf_sim.dissolve([\"ID\", \"time_group\", \"filename\"]).convex_hull.reset_index().set_geometry(0)\n",
    "sim_time_counter = gdf_sim.groupby(['ID','time_group', \"filename\"])['timestamp'].count().reset_index()\n",
    "sim_homeranges = pd.merge(\n",
    "    left=sim_homeranges, \n",
    "    right=sim_time_counter,\n",
    "    how='left',\n",
    "    left_on=['ID', 'time_group', 'filename'],\n",
    "    right_on=['ID', 'time_group', 'filename'])\n",
    "\n",
    "gps_homeranges = gdf_gps.dissolve([\"Deer ID\", \"time_group\"]).convex_hull.reset_index().set_geometry(0)\n",
    "gps_time_counter = gdf_gps.groupby(['Deer ID','time_group'])['timestamp'].count().reset_index()\n",
    "gps_homeranges = pd.merge(\n",
    "    left=gps_homeranges, \n",
    "    right=gps_time_counter,\n",
    "    how='left',\n",
    "    left_on=['Deer ID', 'time_group'],\n",
    "    right_on=['Deer ID', 'time_group'])\n",
    "\n",
    "deer_info = gdf_gps[['Deer ID', 'sex']].drop_duplicates().reset_index(drop=True)\n",
    "gps_homeranges = pd.merge(\n",
    "    left=gps_homeranges, \n",
    "    right=deer_info[['sex','Deer ID']],\n",
    "    how='left',\n",
    "    left_on=['Deer ID'],\n",
    "    right_on=['Deer ID'])\n",
    "\n",
    "gps_homeranges = gps_homeranges.rename(columns = {'timestamp':'samples_in_group' })\n",
    "sim_homeranges = sim_homeranges.rename(columns = {'timestamp':'samples_in_group'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49980189-056f-4ac7-bb7a-f9cd6d6320de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_homeranges[\"area\"] = sim_homeranges[0].area/ 10**6 # Square km's\n",
    "gps_homeranges[\"area\"] = gps_homeranges[0].area/ 10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903d952e-8011-4e05-a837-040a493e1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_homeranges.to_file(gps_hr_gpkg, layer='agent_location', driver='GPKG')\n",
    "sim_homeranges.to_file(sim_hr_gpkg, layer='agent_location', driver='GPKG') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f4734-20ab-4fa0-bde1-ef017cd9e93e",
   "metadata": {},
   "source": [
    "So now that the homeranges are written to geopackage files, they can be visualised in QGIS. Here's a quick example:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd83c8-ee16-4a68-a3fb-217aed152114",
   "metadata": {},
   "source": [
    "## Homerange sizes\n",
    "Are the monthly home range areas similar to the GPS data? Let's plot the monthly home range area (convex hull of GPS/Simulated points per agent, per month). This homerange area is not specified in the model parameters and so \"should\" be similar if the model is behaving as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8ec198-456b-40bb-a3a9-1feedd3d5e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_homeranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537cee4-d431-45a8-b387-325f24237198",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "\n",
    " \n",
    "fig.add_trace(go.Histogram(x=gps_homeranges[\"samples_in_group\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = 'GPS Data'))\n",
    "\n",
    "for filepath in sim_homeranges['filename'].unique():  \n",
    "    df = sim_homeranges[sim_homeranges['filename'] == filepath]\n",
    "    \n",
    "    fig.add_trace(go.Histogram(x=df[\"samples_in_group\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = f'{filepath} Data'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Monthly Number of Rows/Points in HomeRange\"\n",
    "    ),  \n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Normalised Points Per Month\"\n",
    "        )\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Number of Points used for HomeRange per month\"\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Movement Model\"\n",
    "        )\n",
    "    ), \n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a58ffc2-3777-4a4a-9ca3-8ff588790e9b",
   "metadata": {},
   "source": [
    "The above figure shows that the simulated data is, obviously, more regular than the GPS data. There are a few GPS devices that have far fewer samples in a given month than expected. These few GPS points would alter the expected monthly home range size. Let's drop all rows that have a points/month that is too low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296783ae-3a17-4ac8-a61d-f2a41e990867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Some data filtering\n",
    "\n",
    "gps_homeranges = gps_homeranges[gps_homeranges['samples_in_group'] > 600]\n",
    "gps_homeranges = gps_homeranges[gps_homeranges['area'] < 40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7c4c0-acfe-42c9-82d0-df2cdfb19703",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "\n",
    " \n",
    "fig.add_trace(go.Histogram(x=gps_homeranges[\"area\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = 'GPS Data'))\n",
    "\n",
    "for filepath in sim_homeranges['filename'].unique():  \n",
    "    df = sim_homeranges[sim_homeranges['filename'] == filepath]\n",
    "    \n",
    "    fig.add_trace(go.Histogram(x=df[\"area\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = f'{filepath} Data'))\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Monthly Home Range Area Histogram\"\n",
    "    ),  \n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Normalised Monthly Home Ranges\"\n",
    "        )\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Home Range Area [km^2]\"\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Data Source\"\n",
    "        )\n",
    "    ), \n",
    ")\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b285d1b-b0ad-4cb5-a2c3-6e8c19f33142",
   "metadata": {},
   "source": [
    "The above figure shows that the GPS data home ranges are much smaller than any of the modelled home ranges... Not a good result..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da94258-dc88-46fa-8436-4abf02e3d144",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "\n",
    "fig.add_trace(go.Histogram(x=gps_homeranges[gps_homeranges['sex']=='f'][\"area\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = 'Female GPS Data'))\n",
    "\n",
    "fig.add_trace(go.Histogram(x=gps_homeranges[gps_homeranges['sex']=='m'][\"area\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = 'Male GPS Data'))\n",
    " \n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Monthly Home Range Area Histogram\"\n",
    "    ),  \n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Normalised Monthly Home Ranges\"\n",
    "        )\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Home Range Area [km^2]\"\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Data Source\"\n",
    "        )\n",
    "    ), \n",
    ")\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa7d01-5a1b-41c9-8dde-6d860074759b",
   "metadata": {},
   "source": [
    "The above figure shows that the male/female homeranges in the GPS data is significantly different. It would therefor make sense to model the male/female movement parameters differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ba3e2-21ff-474c-bd72-9ca08d25dafa",
   "metadata": {},
   "source": [
    "## Those same step and turn calcs again\n",
    "\n",
    "Below is the method used to calculate step and turn values from a timeseries of points. It must be known that the values calculated are often for the previous points, so when looking at it with agents mixed up it'll just look plain wrong "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f2b10-24ef-466d-b1f5-bf6e7af17a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_heading(lon_1, lat_1,\n",
    "                 lon_2, lat_2,\n",
    "                 lon_3, lat_3):\n",
    "    \n",
    "    '''\n",
    "    Calculate the turning angle Theta_T to go from t-1 > t > t+1 \n",
    "    or if Centroid is used as lon/lat_3 then  it should return\n",
    "    Theta_Ct\n",
    "    '''    \n",
    "    dx = lon_2 - lon_1\n",
    "    dy = lat_2 - lat_1\n",
    "    angle_radians_1 = np.arctan2(dx, dy) # Compass direction of travel between current_pos and centroid \n",
    "\n",
    "    dx = lon_3 - lon_2\n",
    "    dy = lat_3 - lat_2\n",
    "    angle_radians_2 = np.arctan2(dx, dy) # Compass direction of travel between current_pos and centroid \n",
    "    \n",
    "    turn_angle = (angle_radians_2 - angle_radians_1) % (2 * np.pi)\n",
    "\n",
    "    turn_angle = np.mod(turn_angle + np.pi, 2*np.pi) - np.pi\n",
    "     \n",
    "    return turn_angle\n",
    "\n",
    "def calc_step_and_turn(gdf_sim):\n",
    "    gdf_sim = gdf_sim.to_crs('5070')\n",
    "    gdf_sim['lon'] = gdf_sim.geometry.x\n",
    "    gdf_sim['lat'] = gdf_sim.geometry.y\n",
    "    gdf_sim = gdf_sim.to_crs(sim_projection)\n",
    "    \n",
    "    gdf_sim['geometry_prev'] = gdf_sim.groupby('ID')['geometry'].shift(1) \n",
    "    gdf_sim['geometry_next'] = gdf_sim.groupby('ID')['geometry'].shift(-1) \n",
    "    gdf_sim = gdf_sim.dropna(subset=['geometry_prev','geometry_next']) \n",
    "    \n",
    "    gdf_sim['step_distance'] = gdf_sim.distance(gdf_sim['geometry_next'])*30\n",
    "    gdf_sim['turn_angle']  = gdf_sim.apply(lambda row: calc_heading(row['geometry_prev'].x, row['geometry_prev'].y, \n",
    "                                                                    row['geometry'].x, row['geometry'].y, \n",
    "                                                                    row['geometry_next'].x, row['geometry_next'].y, \n",
    "                                                                    ), axis=1) \n",
    "    \n",
    "    \n",
    "    return gdf_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe57322-fda6-465e-9d1d-aee62f4bca15",
   "metadata": {},
   "source": [
    "## Look at Movement Params\n",
    "\n",
    "Similar to the initial data analysis, lets take a look at the step and turn distributions and then some other statistical measures like home range size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242fd6b3-e515-46fe-a990-0f9e8679b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sim = calc_step_and_turn(gdf_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0426ba8-a7d3-4e1c-99ad-b8f1982bbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure() \n",
    "\n",
    "fig.add_trace(go.Histogram(x=gdf_gps[\"turn_angle\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = 'GPS Turn Angles'))\n",
    "\n",
    "for filepath in gdf_sim['filename'].unique(): \n",
    "    df = gdf_sim[gdf_sim['filename'] == filepath]\n",
    "    fig.add_trace(go.Histogram(x=df[\"turn_angle\"],\n",
    "                               histnorm='probability density',\n",
    "                               name = f'{filepath} Turn Angles'))\n",
    "\n",
    "fig.update_traces(xbins=dict( # bins used for histogram\n",
    "        start=-3.15,\n",
    "        end=3.15,\n",
    "        size=0.05\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Normalised Histogram of Turn Angles\"\n",
    "    ),  \n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Normalised Count\"\n",
    "        )\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Turn Angle [Rad]\"\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Data Source\"\n",
    "        )\n",
    "    ), \n",
    ")\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.5)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1bf08b-2025-4a52-947a-6a6dbf10e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "\n",
    "fig.add_trace(go.Histogram(x=gdf_gps[\"step_distance\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = 'GPS Data'))\n",
    "\n",
    "for filepath in gdf_sim['filename'].unique(): \n",
    "    df = gdf_sim[gdf_sim['filename'] == filepath]\n",
    "    fig.add_trace(go.Histogram(x=df[\"step\"],\n",
    "                               histnorm='probability density',\n",
    "                               name = f'{filepath}'))\n",
    "     \n",
    "\n",
    "fig.update_traces(xbins=dict( # bins used for histogram\n",
    "        start=0,\n",
    "        end=1000,\n",
    "        size=10\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Normalised Histogram of Step Distances\"\n",
    "    ),  \n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Normalised Count\"\n",
    "        )\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Step Distance [meter]\"\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Data Source\"\n",
    "        )\n",
    "    ), \n",
    ")\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.5)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca68f1e-6a57-46e5-a3a5-e94022ea7aac",
   "metadata": {},
   "source": [
    "## HMM Step and Turns vs Behavioural State\n",
    "The step and turn histograms for HMM doens't look right... There seems to be something off with it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab3455-76db-48bb-bf2e-9aa3537569b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_sim = gdf_sim[gdf_sim['filename'] == 'LocalRun']\n",
    "hmm_sim[['filename','turn','turn_angle','step','step_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90109f51-b940-4720-aa53-419467e095ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e44e0d-6063-4b60-ad46-6ed21fcc1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure() \n",
    "\n",
    "fig.add_trace(go.Histogram(x=gdf_gps[\"turn_angle\"],\n",
    "                           histnorm='probability density',\n",
    "                           name = 'GPS Data'))\n",
    "\n",
    "states = hmm_sim['Behaviour State'].unique()\n",
    "for behaviour_state in states: \n",
    "    df = hmm_sim[hmm_sim['Behaviour State'] == behaviour_state]\n",
    "    fig.add_trace(go.Histogram(x=df[\"turn_angle\"],\n",
    "                               histnorm='probability density',\n",
    "                               name = f'HMM -- {behaviour_state}'))\n",
    "         \n",
    "\n",
    "# fig.update_traces(xbins=dict( # bins used for histogram\n",
    "#         start=0,\n",
    "#         end=1000,\n",
    "#         size=10\n",
    "#     ))\n",
    "\n",
    "\n",
    "fig.update_traces(xbins=dict( # bins used for histogram\n",
    "        start=-3.15,\n",
    "        end=3.15,\n",
    "        size=0.05\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Normalised Histogram of Step Distances\"\n",
    "    ),  \n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Normalised Count\"\n",
    "        )\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Step Distance [meter]\"\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Data Source\"\n",
    "        )\n",
    "    ), \n",
    ")\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61f57f6-0506-4aaf-bbbb-48399fb6cafb",
   "metadata": {},
   "source": [
    "## Timeseries Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d653e2-04c1-4ee3-856c-a054289e718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sim[['step','step_distance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be86afa2-831f-4a31-82d3-bef5374f12a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_grouped = gdf_sim.groupby(['timestamp', 'Disease State']).size().reset_index(name='count')\n",
    "fig = px.line(df_grouped, x='timestamp', y='count', color='Disease State',\n",
    "              title='Count of Categories Over Time',\n",
    "              labels={'timestamp': 'Timestamp', 'count': 'Count', 'category': 'Category'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8545adf-1469-442f-a6a1-f83ec0f81ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295ab6d-7799-4cd5-93f3-1914f3a191f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()  \n",
    "\n",
    "for filepath in gdf_sim['filename'].unique(): \n",
    "    df = gdf_sim[gdf_sim['filename'] == filepath] \n",
    "    df_grouped = df.groupby(['timestamp', 'Behaviour State']).size().reset_index(name='count')\n",
    "    states = df_grouped['Behaviour State'].unique()\n",
    "    for behaviour_state in states:\n",
    "        df_state = df_grouped[df_grouped['Behaviour State'] == behaviour_state] \n",
    "        fig.add_trace(go.Scatter(x=df_state[\"timestamp\"],\n",
    "                                 y=df_state['count'],\n",
    "                                   name = f'{filepath} -- {behaviour_state}'))\n",
    "      \n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "        text=\"Timeseries of Behaviour State Counts\"\n",
    "    ),  \n",
    "    yaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Agent Count\"\n",
    "        )\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        title=dict(\n",
    "            text=\"Timestamp\"\n",
    "        )\n",
    "    ),\n",
    "    legend=dict(\n",
    "        title=dict(\n",
    "            text=\"Data Source\"\n",
    "        )\n",
    "    ), \n",
    ")\n",
    "fig.update_layout(barmode='overlay')\n",
    "fig.update_traces(opacity=0.75)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc0f35f-587b-4b1c-aaab-e23ec214f6d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a5e791-7f41-42d0-9ade-4ee685aa8515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_grouped = gdf_sim.groupby(['timestamp'])['step_distance'].mean().reset_index(name='count')\n",
    "fig = px.line(df_grouped, x='timestamp', y='count', \n",
    "              # color='Disease State',\n",
    "              title='Average Step Distance Over Time',\n",
    "              labels={'timestamp': 'Timestamp', 'count': 'Average Step Distance', 'category': 'Category'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61f5cf-7918-42ef-86b7-1947041a1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_grouped = gdf_sim.groupby(['timestamp'])['turn_angle'].mean().reset_index(name='count')\n",
    "fig = px.line(df_grouped, x='timestamp', y='count', \n",
    "              # color='Disease State',\n",
    "              title='Average Turn Angle Over Time',\n",
    "              labels={'timestamp': 'Timestamp', 'count': 'Average Step Distance', 'category': 'Category'})\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb62181-9804-4b6c-b946-cc76c3e190ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
